{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 - infer interactions then plot\n",
    "Katharine Z. Coyte January 2020\n",
    "\n",
    "Infer interactions between microbes by fitting data to a generalized lotka volterra model using bayesian spike-and-slab variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch, Circle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#import scipy\n",
    "#from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pymc3 as pm\n",
    "\n",
    "import jan_miseq_functions as jnf\n",
    "import infer_interactions_clean as iic\n",
    "import drug_info as di\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl='genus' \n",
    "prevalence_threshold = 30\n",
    "relative_abundance_threshold = 0.005 # Note we filter out any genera with low prevalence and abundance\n",
    "\n",
    "antibacterials, antifungals, vaccines = di.load_drug_types()\n",
    "all_meds = pd.read_excel('allMeds_jan2020.xlsx')\n",
    "\n",
    "data_bac, otu_table_bac = jnf.load_microbiome_data(file_name = '20190207_NICU_rDNA_zOTU-table_mod2.xlsx',\n",
    "                         sheet_name = 'bac16S')\n",
    "\n",
    "data_fun, otu_table_fun = jnf.load_microbiome_data(file_name = '20190207_NICU_rDNA_zOTU-table_mod2.xlsx',\n",
    "                         sheet_name = 'ITS1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various additional data processing - calculating geometric means, cleaning column names etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean and reorganize data ###\n",
    "data_bacteria = jnf.process_NICU_data_for_plotting(data_bac, otu_table_bac, 'Bacteria', tl)\n",
    "data_fungi = jnf.process_NICU_data_for_plotting(data_fun, otu_table_fun, 'Fungi', tl)\n",
    "data = pd.concat([data_bacteria, data_fungi.drop(['babyid', 'day'],1)],1, sort=False).fillna(0)\n",
    "otu_table = pd.concat([otu_table_bac, otu_table_fun])\n",
    "\n",
    "relative_bacteria = iic.get_relative_abundances(data_bacteria)\n",
    "relative_fungi = iic.get_relative_abundances(data_fungi)\n",
    "\n",
    "my_bacteria = iic.filter_for_prevalence(relative_bacteria, prevalence_threshold, relative_abundance_threshold)\n",
    "my_fungi = iic.filter_for_prevalence(relative_fungi, prevalence_threshold, relative_abundance_threshold)\n",
    "\n",
    "current_dataset = pd.concat([data.loc[:, ['day','babyid']],\n",
    "                             data[my_bacteria],\n",
    "                             data[my_fungi]], 1, sort=False)\n",
    "current_dataset.day = current_dataset.day.astype(float)\n",
    "\n",
    "\n",
    "### Calculate geometric means and dxdt ###\n",
    "all_geo_mean_df, all_dlog_dt_df =  iic.calculate_dxdt(current_dataset,\n",
    "                                                      all_meds,\n",
    "                                                      0,\n",
    "                                                     antibacterials,\n",
    "                                                     antifungals)\n",
    "all_Y = all_dlog_dt_df.dropna().drop(['babyid','day'],1)\n",
    "all_X = all_geo_mean_df\n",
    "all_X = all_X.loc[all_Y.index,:]\n",
    "all_X = iic.clean_column_names(all_X)\n",
    "all_Y = iic.clean_column_names(all_Y)\n",
    "\n",
    "\n",
    "### Remove brackets, drop any antibiotics that occur fewer than 5 times ###\n",
    "all_X = all_X.rename(columns={'Zosyn_(Piperacillin/tazobactam)':'Zosyn'})\n",
    "copy_all_X = all_X.copy()\n",
    "for col in all_X.columns:\n",
    "    if len(all_X.loc[all_X[col]>0,:]) < 5:\n",
    "        copy_all_X = copy_all_X.drop(col,1) \n",
    "all_X = copy_all_X\n",
    "\n",
    "\n",
    "### Rename for fitting ###\n",
    "my_bacteria = ['Escherichia_Shigella' if x=='Escherichia-Shigella' else x for x in my_bacteria]\n",
    "my_bacteria = ['Clostridium_sensu_stricto_1' if x=='Clostridium sensu stricto 1' else x for x in my_bacteria]\n",
    "my_bacteria = ['Clostridiaceae_1' if x=='Clostridiaceae 1' else x for x in my_bacteria]\n",
    "\n",
    "my_list = ['Escherichia_Shigella',\n",
    "           'Klebsiella',\n",
    "           'Staphylococcus',\n",
    "           'Enterococcus',\n",
    "           'Candida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer microbe microbe interactions\n",
    "\n",
    "Use spike-and-slab variable selection to identify interactions most consistently apparent in our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_X = all_X.copy()\n",
    "save_all_Y = all_Y.copy()\n",
    "\n",
    "store_all_interactions = pd.DataFrame()\n",
    "store_intercepts = pd.DataFrame()\n",
    "\n",
    "tmp = save_all_X.copy()\n",
    "tmp[tmp>0]=1\n",
    "\n",
    "for focal_species in all_Y.columns:\n",
    "    \n",
    "    my_all_X = save_all_X.copy()\n",
    "    my_all_Y = save_all_Y.copy()\n",
    "\n",
    "    # Drop samples without focal species        \n",
    "    my_all_X = my_all_X.drop(my_all_X.loc[my_all_X[focal_species] ==0,:].index)\n",
    "    my_all_Y = my_all_Y.loc[my_all_X.index,:].copy()\n",
    "        \n",
    "    if len(my_all_Y) > 10:\n",
    "\n",
    "        # Standardize all X variables\n",
    "        tmp = StandardScaler().fit_transform(my_all_X)\n",
    "        my_all_X = pd.DataFrame(tmp, index = my_all_X.index, columns = my_all_X.columns)\n",
    "        \n",
    "        \n",
    "        model = pm.Model()\n",
    "        X_taxa = my_all_X.copy()[my_all_Y.columns]\n",
    "        X_drugs = my_all_X.copy().drop(X_taxa.columns, 1)\n",
    "               \n",
    "        X_taxa = X_taxa.drop(X_taxa.loc[:,X_taxa.sum()==0].columns,1)\n",
    "        X_drugs = X_drugs.drop(X_drugs.loc[:,X_drugs.sum()==0].columns,1)\n",
    "\n",
    "        y = my_all_Y[focal_species].copy()\n",
    "\n",
    "        \n",
    "        # Set up priors for model\n",
    "        \n",
    "        Sigma_taxa = .5 * np.matmul(X_taxa.T.values, X_taxa.values)\n",
    "        Sigma_taxa += np.diag(np.diag(Sigma_taxa))\n",
    "        Sigma_taxa = np.linalg.inv(Sigma_taxa)\n",
    "        #Sigma_taxa = np.identity(len(Sigma_taxa)) # alternatively use identity matrix (results same)\n",
    "        \n",
    "        Sigma_drugs = .5 * np.matmul(X_drugs.T.values, X_drugs.values)\n",
    "        Sigma_drugs += np.diag(np.diag(Sigma_drugs))\n",
    "        Sigma_drugs = np.linalg.inv(Sigma_drugs)\n",
    "        #Sigma_drugs = np.identity(len(Sigma_drugs)) # alternatively use identity matrix (results same)\n",
    "        \n",
    "        # For calculating growth rate initialisation\n",
    "        X_growth = my_all_X.copy()\n",
    "        X_growth = sm.add_constant(X_growth)\n",
    "        Y = my_all_Y[focal_species].copy()\n",
    "        r_model = sm.OLS(Y,X_growth)\n",
    "    \n",
    "        results = r_model.fit()\n",
    "        init_r = results.params['const']\n",
    "        if init_r < 0:\n",
    "            init_r = 0\n",
    "        init_r_std= np.std(results.params) # inflate initial prior for intercept\n",
    "    \n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            \n",
    "            xi_taxa = pm.Bernoulli('xi_taxa', .5, shape=X_taxa.shape[1])\n",
    "            tau_taxa = pm.HalfCauchy('tau_taxa', 1)\n",
    "            beta_taxa = pm.MvNormal('beta_taxa', 0, tau_taxa * Sigma_taxa, shape=X_taxa.shape[1])\n",
    "            mean_taxa = pm.math.dot(X_taxa, xi_taxa * beta_taxa)\n",
    "            \n",
    "            xi_drugs = pm.Bernoulli('xi_drugs', .5, shape=X_drugs.shape[1])\n",
    "            tau_drugs = pm.HalfCauchy('tau_drugs', 1)\n",
    "            beta_drugs = pm.MvNormal('beta_drugs', 0, tau_drugs * Sigma_drugs, shape=X_drugs.shape[1])\n",
    "            mean_drugs = pm.math.dot(X_drugs, xi_drugs * beta_drugs)\n",
    "            \n",
    "            my_sigma = pm.HalfNormal('my_sigma', 10) \n",
    "\n",
    "            \n",
    "            intercp = pm.Bound(pm.Normal, lower=0.0)('intercp', mu=1.0, tau=(init_r_std**2)*1e2)\n",
    "            \n",
    "            my_var = pm.Normal('my_var', mean_drugs + mean_taxa + intercp, my_sigma, observed=y)\n",
    "\n",
    "            lasso_normal_trace_s = pm.sample(draws =10000,tune=2500, init='adapt_diag', cores=-1)\n",
    "\n",
    "\n",
    "\n",
    "        my_summary = pm.summary(lasso_normal_trace_s)\n",
    "        \n",
    "        store_intercepts.loc[focal_species, 'ic'] = my_summary.loc['intercp','mean']\n",
    "        \n",
    "        new_summary = pd.DataFrame()\n",
    "        for ix, val in enumerate(X_taxa.columns):\n",
    "            cur_index = 'beta_taxa__' + str(ix)\n",
    "            cur_mean = my_summary.loc[cur_index, 'mean']\n",
    "            cur_sd = my_summary.loc[cur_index, 'sd']\n",
    "            try:\n",
    "                rename_val = val + '_' + otu_table.loc[val, 'family']\n",
    "            except:\n",
    "                rename_val = val\n",
    "            new_summary.loc[rename_val, 'cur_mean'] = cur_mean\n",
    "            new_summary.loc[rename_val, 'cur_sd'] = cur_sd\n",
    "            store_all_interactions.loc[focal_species, val] = cur_mean\n",
    "\n",
    "\n",
    "\n",
    "        for ix, val in enumerate(X_drugs.columns):\n",
    "            cur_index = 'beta_drugs__' + str(ix)\n",
    "            cur_mean = my_summary.loc[cur_index, 'mean']\n",
    "            cur_sd = my_summary.loc[cur_index, 'sd']\n",
    "            try:\n",
    "                rename_val = val + '_' + otu_table.loc[val, 'family']\n",
    "            except:\n",
    "                rename_val = val\n",
    "            new_summary.loc[rename_val, 'cur_mean'] = cur_mean\n",
    "            new_summary.loc[rename_val, 'cur_sd'] = cur_sd\n",
    "            store_all_interactions.loc[focal_species, val] = cur_mean\n",
    "\n",
    "\n",
    "        try:\n",
    "            print(focal_species, otu_table.loc[focal_species, 'family'])\n",
    "        except:\n",
    "            print(focal_species)\n",
    "        sns.set_style('white')\n",
    "        plt.figure(figsize=(10,10))\n",
    "\n",
    "        plt.scatter(x = new_summary.cur_mean, y = new_summary.index, c='orange')\n",
    "        plt.barh(y = new_summary.index,\n",
    "                width = new_summary.cur_mean,\n",
    "                height=0.0,\n",
    "                xerr= new_summary.cur_sd)\n",
    "        plt.plot([0,0],[-0.5,len(new_summary)+0.0],'gray')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot interaction network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,figsize=(8,6.5))\n",
    "\n",
    "### Split interactions into positive and negative for plotting ###\n",
    "cur_matrix = store_all_interactions.copy()\n",
    "cur_matrix[abs(cur_matrix) <0.01]=0 # filter out very weak interactions\n",
    "cur_matrix = cur_matrix.loc[my_list, my_list].T\n",
    "cm_pos = cur_matrix.copy()\n",
    "cm_pos[cm_pos<0]=0\n",
    "cm_neg = cur_matrix.copy()\n",
    "cm_neg[cm_neg>0]=0\n",
    "\n",
    "\n",
    "### Plot positive edges ###\n",
    "G=nx.from_numpy_matrix(np.array(cm_pos),\n",
    "                       create_using=nx.MultiDiGraph())\n",
    "pos = nx.layout.circular_layout(G)\n",
    "pos[4] = (pos[4][0] + 0.08, pos[4][1]-0.7)\n",
    "\n",
    "M = G.number_of_edges()\n",
    "edge_colors = np.zeros(M)\n",
    "for ix, e in enumerate(G.edges(data=True)):\n",
    "    edge_colors[ix] = abs(e[2]['weight'])\n",
    "\n",
    "for cix, cn in enumerate(G.edges()):\n",
    "    e = FancyArrowPatch(pos[cn[0]],\n",
    "                        pos[cn[1]],\n",
    "                            arrowstyle='-|>',\n",
    "                            connectionstyle='arc3,rad=0.25',\n",
    "                            mutation_scale=35.0,\n",
    "                            lw=7.5,\n",
    "                            color=cm.Blues(edge_colors[cix]*5),\n",
    "                            shrinkA=25,\n",
    "                            shrinkB=25)\n",
    "    ax.add_patch(e)\n",
    "\n",
    "    \n",
    "### Plot negative edges ###\n",
    "G=nx.from_numpy_matrix(np.array(cm_neg),\n",
    "                       create_using=nx.MultiDiGraph())\n",
    "\n",
    "M = G.number_of_edges()\n",
    "edge_colors = np.zeros(M)\n",
    "for ix, e in enumerate(G.edges(data=True)):\n",
    "    edge_colors[ix] = abs(e[2]['weight'])\n",
    "\n",
    "for cix, cn in enumerate(G.edges()):\n",
    "    e = FancyArrowPatch(pos[cn[0]],\n",
    "                        pos[cn[1]],\n",
    "                            arrowstyle='-[',\n",
    "                            connectionstyle='arc3,rad=0.25',\n",
    "                            mutation_scale=12.0,\n",
    "                            lw=7.5,\n",
    "                            color=cm.Reds(edge_colors[cix]*8),\n",
    "                            shrinkA=25,\n",
    "                            shrinkB=25)\n",
    "    ax.add_patch(e)\n",
    "\n",
    "\n",
    "### Plot nodes ###\n",
    "node_colors = ['red', 'dodgerblue', 'gold', 'green', 'brown']\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=range(4),node_shape='o', node_size=250, node_color= node_colors[0:4])\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=[4],node_shape='^', node_size=250, node_color=['brown'])\n",
    "    \n",
    "    \n",
    "### Fix axis ###\n",
    "ax.set_xlim([-1.1,1.1])\n",
    "ax.set_ylim([-1.1,1.1])\n",
    "plt.axis('off')\n",
    "plot_margin = 0.5\n",
    "x0, x1, y0, y1 = plt.axis()\n",
    "plt.axis((x0 - plot_margin,\n",
    "          x1 + plot_margin,\n",
    "          y0 -plot_margin-0.3,\n",
    "          y1 + 0.09))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate histogram of antibiotic and antifungal interactions, split by kingdom / drug type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get antimicrobial interactions\n",
    "abx_matrix = store_all_interactions.copy()\n",
    "abx_matrix = abx_matrix.drop(my_bacteria,1)\n",
    "abx_matrix = abx_matrix.drop(my_fungi,1).fillna(0)\n",
    "abx_matrix[abs(abx_matrix) <0.01]=0\n",
    "\n",
    "## Split up antimicrobial matrix\n",
    "# bacteria / antibiotics\n",
    "bac_abx = abx_matrix.loc[my_bacteria,antibacterials].copy().dropna(1)\n",
    "store_abx_tmp = pd.DataFrame()\n",
    "for col in bac_abx.columns:\n",
    "    tmp = bac_abx.loc[:,col]\n",
    "    store_abx_tmp = pd.concat([store_abx_tmp, pd.DataFrame(tmp[tmp!=0].get_values())])\n",
    "store_abx_tmp = store_abx_tmp.reset_index().drop(['index'],1)\n",
    "\n",
    "# bacteria / antifungals\n",
    "bac_anf = abx_matrix.loc[my_bacteria,antifungals].copy().dropna(1)\n",
    "store_anf_tmp = pd.DataFrame()\n",
    "for col in bac_anf.columns:\n",
    "    tmp = bac_anf.loc[:,col]\n",
    "    store_anf_tmp = pd.concat([store_anf_tmp, pd.DataFrame(tmp[tmp!=0].get_values())])\n",
    "store_anf_tmp = store_anf_tmp.reset_index().drop(['index'],1)\n",
    "\n",
    "# fungi / antibiotics\n",
    "fun_abx = abx_matrix.loc[my_fungi,antibacterials].copy().drop(['Aspergillus'])\n",
    "fun_abx =fun_abx.dropna(1)\n",
    "store_abx_tmp_fun = pd.DataFrame()\n",
    "for col in fun_abx.columns:\n",
    "    tmp = fun_abx.loc[:,col]\n",
    "    store_abx_tmp_fun = pd.concat([store_abx_tmp_fun, pd.DataFrame(tmp[tmp!=0].get_values())])\n",
    "store_abx_tmp_fun = store_abx_tmp_fun.reset_index().drop(['index'],1)\n",
    "\n",
    "# fungi / antifungals\n",
    "fun_anf = abx_matrix.loc[my_fungi,antifungals].copy().drop(['Aspergillus'])\n",
    "fun_anf =fun_anf.dropna(1)\n",
    "store_anf_tmp_fun = pd.DataFrame()\n",
    "for col in fun_anf.columns:\n",
    "    tmp = fun_anf.loc[:,col]\n",
    "    store_anf_tmp_fun = pd.concat([store_anf_tmp_fun, pd.DataFrame(tmp[tmp!=0].get_values())])\n",
    "store_anf_tmp_fun = store_anf_tmp_fun.reset_index().drop(['index'],1)\n",
    "\n",
    "\n",
    "# Plot separate histograms\n",
    "fig, ax = plt.subplots(2,1, figsize=(5,5))\n",
    "\n",
    "thresh_val=0.05\n",
    "store_abx_tmp[store_abx_tmp<-thresh_val]=-thresh_val\n",
    "store_abx_tmp[store_abx_tmp>thresh_val]=thresh_val\n",
    "\n",
    "store_anf_tmp[store_anf_tmp<-thresh_val]=-thresh_val\n",
    "store_anf_tmp[store_anf_tmp>thresh_val]=thresh_val\n",
    "\n",
    "store_abx_tmp_fun[store_abx_tmp_fun<-thresh_val]=-thresh_val\n",
    "store_abx_tmp_fun[store_abx_tmp_fun>thresh_val]=thresh_val\n",
    "\n",
    "store_anf_tmp_fun[store_anf_tmp_fun<-thresh_val]=-thresh_val\n",
    "store_anf_tmp_fun[store_anf_tmp_fun>thresh_val]=thresh_val\n",
    "\n",
    "\n",
    "my_bins=np.linspace(-3,3,51)*0.1\n",
    "ax[0].hist(store_abx_tmp.values,\n",
    "         density=False,\n",
    "         bins=my_bins,\n",
    "        histtype='stepfilled',\n",
    "          color=[179/255,129/255,176/255])\n",
    "\n",
    "ax0_2 = ax[0].twinx() \n",
    "ax[0].hist(store_anf_tmp.values,\n",
    "         density=False,\n",
    "         bins=my_bins,\n",
    "        alpha=0.75,\n",
    "        histtype='stepfilled',\n",
    "          color=[182/255,212/255,146/255])\n",
    "ax[0].plot([0,0],[0,6],'k--')\n",
    "ax[0].set_xlim([-0.075,0.075])\n",
    "\n",
    "ax[1].hist(store_abx_tmp_fun.values,\n",
    "         density=False,\n",
    "         bins=my_bins,\n",
    "        histtype='stepfilled',\n",
    "          color=[179/255,129/255,176/255])\n",
    "ax1_2 = ax[1].twinx() \n",
    "\n",
    "ax[1].hist(store_anf_tmp_fun.values,\n",
    "         density=False,\n",
    "         bins=my_bins,\n",
    "        alpha=0.75,\n",
    "        histtype='stepfilled',\n",
    "        color=[182/255,212/255,146/255])\n",
    "ax[1].plot([0,0],[0,6],'k--')\n",
    "ax[1].set_xlim([-0.075,0.075])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate proportion of different interaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just taxa interactions\n",
    "cur_matrix = store_all_interactions.copy()\n",
    "cur_matrix = cur_matrix.drop(abx_matrix.columns, 1)\n",
    "cur_matrix = cur_matrix.loc[:, cur_matrix.index]\n",
    "cur_matrix[abs(cur_matrix) <0.01]=0\n",
    "\n",
    "\n",
    "# Go through and count interactions\n",
    "count_ints = pd.DataFrame(0, index = ['interaction'], columns = ['-/-', '-/o', '+/-', '+/o', '+/+'])\n",
    "for ix_sp in cur_matrix.index:\n",
    "    for col_sp in cur_matrix.columns:\n",
    "        \n",
    "        if col_sp != ix_sp:\n",
    "        \n",
    "            ci_focal = cur_matrix.loc[ix_sp, col_sp]\n",
    "            ci_pair = cur_matrix.loc[col_sp, ix_sp]\n",
    "\n",
    "            if ci_focal > 0:\n",
    "                if ci_pair > 0:\n",
    "                    count_ints.loc['interaction', '+/+'] = count_ints.loc['interaction', '+/+'] + 1 # pp\n",
    "                if ci_pair < 0:\n",
    "                    count_ints.loc['interaction', '+/-'] = count_ints.loc['interaction', '+/-'] + 1 # pm\n",
    "                if ci_pair == 0:\n",
    "                    count_ints.loc['interaction', '+/o'] = count_ints.loc['interaction', '+/o'] + 1 # po\n",
    "\n",
    "            if ci_focal < 0:\n",
    "                if ci_pair > 0:\n",
    "                    count_ints.loc['interaction', '+/-'] = count_ints.loc['interaction', '+/-'] + 1# mp\n",
    "                if ci_pair < 0:\n",
    "                    count_ints.loc['interaction', '-/-'] = count_ints.loc['interaction', '-/-'] + 1# mm\n",
    "                if ci_pair == 0:\n",
    "                    count_ints.loc['interaction', '-/o'] = count_ints.loc['interaction', '-/o'] + 1# mo\n",
    "\n",
    "            if ci_focal == 0:\n",
    "                if ci_pair > 0:\n",
    "                    count_ints.loc['interaction', '+/o'] = count_ints.loc['interaction', '+/o'] + 1# op\n",
    "                if ci_pair < 0:\n",
    "                    count_ints.loc['interaction', '-/o'] = count_ints.loc['interaction', '-/o'] + 1# om \n",
    "                \n",
    "        \n",
    "# Plot result\n",
    "fig, ax = plt.subplots(1,1, figsize=(2,5))\n",
    "colors = ['darkred', 'tomato', 'khaki', 'royalblue', 'darkblue']\n",
    "count_ints=count_ints/count_ints.sum(1).values[0]\n",
    "count_ints.plot(kind='bar',\n",
    "                stacked=True,\n",
    "                colors = colors,\n",
    "                ax=ax)  \n",
    "ax.set_ylim(0,1)\n",
    "ax.legend(bbox_to_anchor=(01.6, 1.00),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot matrices of all interaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(11.5,7.5))\n",
    "\n",
    "gs = GridSpec(1, 8, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, 0:5])\n",
    "ax2 = fig.add_subplot(gs[0, 5:8])#, sharey=ax1)\n",
    "\n",
    "clusters =  sns.heatmap(cur_matrix.fillna(0),\n",
    "               cmap='RdBu',\n",
    "               center=0,\n",
    "               vmin=-0.05,\n",
    "               vmax=0.05,\n",
    "              square=False, ax=ax1,cbar=True,yticklabels=True,linewidths=0.05,\n",
    "                  linecolor = 'darkslategray',)\n",
    "\n",
    "clusters =  sns.heatmap(abx_matrix.fillna(0),\n",
    "               cmap='RdBu',\n",
    "               center=0,\n",
    "               vmin=-0.05,\n",
    "               vmax=0.05,\n",
    "              square=False,\n",
    "                ax=ax2,\n",
    "              cbar=True,\n",
    "                yticklabels=False,\n",
    "                       linewidths=0.05,\n",
    "                  linecolor = 'darkslategray',)\n",
    "ax1.get_shared_y_axes().join(ax2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
